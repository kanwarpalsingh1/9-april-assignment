{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7aa0f877-f3c6-400b-a96b-253cf862f5a0",
   "metadata": {},
   "source": [
    "Q1. Bayes' theorem is a fundamental theorem in probability theory that describes the probability of an event based on prior knowledge of conditions that might be related to the event.\n",
    "\n",
    "Q2. The formula for Bayes' theorem is:\n",
    "\n",
    "�\n",
    "(\n",
    "�\n",
    "∣\n",
    "�\n",
    ")\n",
    "=\n",
    "�\n",
    "(\n",
    "�\n",
    "∣\n",
    "�\n",
    ")\n",
    "×\n",
    "�\n",
    "(\n",
    "�\n",
    ")\n",
    "�\n",
    "(\n",
    "�\n",
    ")\n",
    "P(A∣B)= \n",
    "P(B)\n",
    "P(B∣A)×P(A)\n",
    "​\n",
    " \n",
    "\n",
    "Where:\n",
    "\n",
    "�\n",
    "(\n",
    "�\n",
    "∣\n",
    "�\n",
    ")\n",
    "P(A∣B) is the probability of event A occurring given that event B has occurred.\n",
    "�\n",
    "(\n",
    "�\n",
    "∣\n",
    "�\n",
    ")\n",
    "P(B∣A) is the probability of event B occurring given that event A has occurred.\n",
    "�\n",
    "(\n",
    "�\n",
    ")\n",
    "P(A) and \n",
    "�\n",
    "(\n",
    "�\n",
    ")\n",
    "P(B) are the probabilities of events A and B occurring independently.\n",
    "Q3. Bayes' theorem is used in practice in various fields, including statistics, machine learning, and artificial intelligence. It is commonly applied in areas such as spam filtering, medical diagnosis, and document classification.\n",
    "\n",
    "Q4. Bayes' theorem provides a way to calculate conditional probabilities. It describes how the probability of an event occurring given some prior knowledge or evidence (conditional probability) can be updated based on new information. In other words, it establishes a relationship between the prior probability of an event and the likelihood of observing evidence given that event.\n",
    "\n",
    "Q5. The choice of which type of Naive Bayes classifier to use for a given problem depends on the nature of the data and the assumptions that can be made about the independence of features. The three main types of Naive Bayes classifiers are:\n",
    "\n",
    "Gaussian Naive Bayes: Assumes that continuous features follow a Gaussian distribution.\n",
    "Multinomial Naive Bayes: Suitable for classification problems with discrete features (e.g., text classification with word counts).\n",
    "Bernoulli Naive Bayes: Assumes that features are binary (e.g., presence or absence of a feature).\n",
    "The choice depends on the distribution of the features in the dataset and the underlying assumptions about their relationship with the target variable.\n",
    "\n",
    "Q6. To predict the class for the new instance with features X1 = 3 and X2 = 4 using Naive Bayes, we can calculate the posterior probabilities for each class (A and B) based on the given frequencies and the equal prior probabilities. Then, we choose the class with the highest posterior probability.\n",
    "\n",
    "Given:\n",
    "�\n",
    "(\n",
    "�\n",
    ")\n",
    "=\n",
    "�\n",
    "(\n",
    "�\n",
    ")\n",
    "=\n",
    "0.5\n",
    "P(A)=P(B)=0.5\n",
    "\n",
    "Using the given frequencies:\n",
    "\n",
    "�\n",
    "(\n",
    "�\n",
    "1\n",
    "=\n",
    "3\n",
    "∣\n",
    "�\n",
    ")\n",
    "=\n",
    "4\n",
    "10\n",
    "=\n",
    "0.4\n",
    "P(X1=3∣A)= \n",
    "10\n",
    "4\n",
    "​\n",
    " =0.4\n",
    "�\n",
    "(\n",
    "�\n",
    "2\n",
    "=\n",
    "4\n",
    "∣\n",
    "�\n",
    ")\n",
    "=\n",
    "3\n",
    "10\n",
    "=\n",
    "0.3\n",
    "P(X2=4∣A)= \n",
    "10\n",
    "3\n",
    "​\n",
    " =0.3\n",
    "�\n",
    "(\n",
    "�\n",
    "1\n",
    "=\n",
    "3\n",
    "∣\n",
    "�\n",
    ")\n",
    "=\n",
    "1\n",
    "10\n",
    "=\n",
    "0.1\n",
    "P(X1=3∣B)= \n",
    "10\n",
    "1\n",
    "​\n",
    " =0.1\n",
    "�\n",
    "(\n",
    "�\n",
    "2\n",
    "=\n",
    "4\n",
    "∣\n",
    "�\n",
    ")\n",
    "=\n",
    "3\n",
    "10\n",
    "=\n",
    "0.3\n",
    "P(X2=4∣B)= \n",
    "10\n",
    "3\n",
    "​\n",
    " =0.3\n",
    "Applying Bayes' theorem:\n",
    "�\n",
    "(\n",
    "�\n",
    "∣\n",
    "�\n",
    "1\n",
    "=\n",
    "3\n",
    ",\n",
    "�\n",
    "2\n",
    "=\n",
    "4\n",
    ")\n",
    "=\n",
    "�\n",
    "(\n",
    "�\n",
    "1\n",
    "=\n",
    "3\n",
    "∣\n",
    "�\n",
    ")\n",
    "×\n",
    "�\n",
    "(\n",
    "�\n",
    "2\n",
    "=\n",
    "4\n",
    "∣\n",
    "�\n",
    ")\n",
    "×\n",
    "�\n",
    "(\n",
    "�\n",
    ")\n",
    "�\n",
    "(\n",
    "�\n",
    "1\n",
    "=\n",
    "3\n",
    ")\n",
    "×\n",
    "�\n",
    "(\n",
    "�\n",
    "2\n",
    "=\n",
    "4\n",
    ")\n",
    "P(A∣X1=3,X2=4)= \n",
    "P(X1=3)×P(X2=4)\n",
    "P(X1=3∣A)×P(X2=4∣A)×P(A)\n",
    "​\n",
    " \n",
    "�\n",
    "(\n",
    "�\n",
    "∣\n",
    "�\n",
    "1\n",
    "=\n",
    "3\n",
    ",\n",
    "�\n",
    "2\n",
    "=\n",
    "4\n",
    ")\n",
    "=\n",
    "0.4\n",
    "×\n",
    "0.3\n",
    "×\n",
    "0.5\n",
    "�\n",
    "(\n",
    "�\n",
    "1\n",
    "=\n",
    "3\n",
    ")\n",
    "×\n",
    "�\n",
    "(\n",
    "�\n",
    "2\n",
    "=\n",
    "4\n",
    ")\n",
    "P(A∣X1=3,X2=4)= \n",
    "P(X1=3)×P(X2=4)\n",
    "0.4×0.3×0.5\n",
    "​\n",
    " \n",
    "\n",
    "Similarly,\n",
    "�\n",
    "(\n",
    "�\n",
    "∣\n",
    "�\n",
    "1\n",
    "=\n",
    "3\n",
    ",\n",
    "�\n",
    "2\n",
    "=\n",
    "4\n",
    ")\n",
    "=\n",
    "�\n",
    "(\n",
    "�\n",
    "1\n",
    "=\n",
    "3\n",
    "∣\n",
    "�\n",
    ")\n",
    "×\n",
    "�\n",
    "(\n",
    "�\n",
    "2\n",
    "=\n",
    "4\n",
    "∣\n",
    "�\n",
    ")\n",
    "×\n",
    "�\n",
    "(\n",
    "�\n",
    ")\n",
    "�\n",
    "(\n",
    "�\n",
    "1\n",
    "=\n",
    "3\n",
    ")\n",
    "×\n",
    "�\n",
    "(\n",
    "�\n",
    "2\n",
    "=\n",
    "4\n",
    ")\n",
    "P(B∣X1=3,X2=4)= \n",
    "P(X1=3)×P(X2=4)\n",
    "P(X1=3∣B)×P(X2=4∣B)×P(B)\n",
    "​\n",
    " \n",
    "\n",
    "Comparing the posterior probabilities, we would predict the new instance to belong to class A since \n",
    "�\n",
    "(\n",
    "�\n",
    "∣\n",
    "�\n",
    "1\n",
    "=\n",
    "3\n",
    ",\n",
    "�\n",
    "2\n",
    "=\n",
    "4\n",
    ")\n",
    ">\n",
    "�\n",
    "(\n",
    "�\n",
    "∣\n",
    "�\n",
    "1\n",
    "=\n",
    "3\n",
    ",\n",
    "�\n",
    "2\n",
    "=\n",
    "4\n",
    ")\n",
    "P(A∣X1=3,X2=4)>P(B∣X1=3,X2=4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082c70c6-4aeb-4fb9-a3fa-cdb902d59cd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
